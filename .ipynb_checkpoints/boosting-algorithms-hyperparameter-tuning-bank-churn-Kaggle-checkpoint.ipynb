{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fDefDHQt8LXC"
   },
   "source": [
    "В цьому домашньому завданні ми знову працюємо з даними з нашого змагання [\"Bank Customer Churn Prediction (DLU Course)\"](https://www.kaggle.com/t/7c080c5d8ec64364a93cf4e8f880b6a0).\n",
    "\n",
    "Тут ми побудуємо рішення задачі класифікації з використанням алгоритмів бустингу: XGBoost та LightGBM, а також використаємо бібліотеку HyperOpt для оптимізації гіперпараметрів."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LhivzW9W8-Dz"
   },
   "source": [
    "0. Зчитайте дані `train.csv` в змінну `raw_df` та скористайтесь наведеним кодом нижче аби розділити дані на трнувальні та валідаційні і розділити дані на ознаки з матириці Х та цільову змінну. Назви змінних `train_inputs, train_targets, train_inputs, train_targets` можна змінити на ті, які Вам зручно.\n",
    "\n",
    "  Наведений скрипт - частина отриманого мною скрипта для обробки даних. Ми тут не викнуємо масштабування та обробку категоріальних змінних, бо хочемо це делегувати алгоритмам, які будемо використовувати. Якщо щось не розумієте в наведених скриптах, рекомендую розібратись: навичка читати код - важлива складова роботи в машинному навчанні."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cKE8RTPf6CRD"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from typing import Tuple, Dict, Any\n",
    "\n",
    "\n",
    "def split_train_val(df: pd.DataFrame, target_col: str, test_size: float = 0.2, random_state: int = 42) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Split the dataframe into training and validation sets.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The raw dataframe.\n",
    "        target_col (str): The target column for stratification.\n",
    "        test_size (float): The proportion of the dataset to include in the validation split.\n",
    "        random_state (int): Random state for reproducibility.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[pd.DataFrame, pd.DataFrame]: Training and validation dataframes.\n",
    "    \"\"\"\n",
    "    train_df, val_df = train_test_split(df, test_size=test_size, random_state=random_state, stratify=df[target_col])\n",
    "    return train_df, val_df\n",
    "\n",
    "\n",
    "def separate_inputs_targets(df: pd.DataFrame, input_cols: list, target_col: str) -> Tuple[pd.DataFrame, pd.Series]:\n",
    "    \"\"\"\n",
    "    Separate inputs and targets from the dataframe.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The dataframe.\n",
    "        input_cols (list): List of input columns.\n",
    "        target_col (str): Target column.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[pd.DataFrame, pd.Series]: DataFrame of inputs and Series of targets.\n",
    "    \"\"\"\n",
    "    inputs = df[input_cols].copy()\n",
    "    targets = df[target_col].copy()\n",
    "    return inputs, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-bHdMJVB4xQR"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cq0JU7MqHgp_"
   },
   "source": [
    "1. В тренувальному та валідаційному наборі перетворіть категоріальні ознаки на тип `category`. Можна це зробити двома способами:\n",
    " 1. `df[col_name].astype('category')`, як було продемонстровано в лекції\n",
    " 2. використовуючи метод `pd.Categorical(df[col_name])`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UPmqo-Mr4yUO"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_LxWkv4o-wMe"
   },
   "source": [
    "2. Навчіть на отриманих даних модель `XGBoostClassifier`. Параметри алгоритму встановіть на свій розсуд, ми далі будемо їх тюнити. Рекомендую тренувати не дуже складну модель.\n",
    "\n",
    "  Опис всіх конфігураційних параметрів XGBoostClassifier - тут https://xgboost.readthedocs.io/en/stable/parameter.html#global-config\n",
    "\n",
    "  **Важливо:** зробіть такі налаштування `XGBoostClassifier` аби він самостійно обробляв незаповнені значення в даних і обробляв категоріальні колонки.\n",
    "\n",
    "  Можна також, якщо працюєте в Google Colab, увімкнути можливість використання GPU (`Runtime -> Change runtime type -> T4 GPU`) і встановити параметр `device='cuda'` в `XGBoostClassifier` для пришвидшення тренування бустинг моделі.\n",
    "  \n",
    "  Після тренування моделі\n",
    "  1. Виміряйте точність з допомогою AUROC на тренувальному та валідаційному наборах.\n",
    "  2. Зробіть висновок про отриману модель: вона хороша/погана, чи є high bias/high variance?\n",
    "  3. Порівняйте якість цієї моделі з тою, що ви отрмали з використанням DecisionTrees раніше. Чи вийшло покращити якість?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_5rDqdDP41hb"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U4hm5qYs_f7x"
   },
   "source": [
    "3. Використовуючи бібліотеку `Hyperopt` і приклад пошуку гіперпараметрів для `XGBoostClassifier` з лекції знайдіть оптимальні значення гіперпараметрів `XGBoostClassifier` для нашої задачі. Задайте свою сітку гіперпараметрів виходячи з тих параметрів, які ви б хотіли перебрати. Поставте кількість раундів в підборі гіперпараметрів рівну **20**.\n",
    "\n",
    "  **Увага!** Для того, аби скористатись hyperopt, нам треба задати функцію `objective`. В ній ми маємо задати loss - це може будь-яка метрика, але бажано використовувтаи ту, яка цільова в вашій задачі. Чим менший лосс - тим ліпша модель на думку hyperopt. Тож, тут нам треба задати loss - негативне значення AUROC. В лекції ми натомість використовували Accuracy.\n",
    "\n",
    "  Після успішного завершення пошуку оптимальних гіперпараметрів\n",
    "    - виведіть найкращі значення гіперпараметрів\n",
    "    - створіть в окремій зміній `final_clf` модель `XGBoostClassifier` з найкращими гіперпараметрами\n",
    "    - навчіть модель `final_clf`\n",
    "    - оцініть якість моделі `final_clf` на тренувальній і валідаційній вибірках з допомогою AUROC.\n",
    "    - зробіть висновок про якість моделі. Чи стала вона краще порівняно з попереднім пунктом (2) цього завдання?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WhR1g9B4433r"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vg77SVWrBBmU"
   },
   "source": [
    "4. Навчіть на наших даних модель LightGBM. Параметри алгоритму встановіть на свій розсуд, ми далі будемо їх тюнити. Рекомендую тренувати не дуже складну модель.\n",
    "\n",
    "  Опис всіх конфігураційних параметрів LightGBM - тут https://lightgbm.readthedocs.io/en/latest/Parameters.html\n",
    "\n",
    "  **Важливо:** зробіть такі налаштування LightGBM аби він самостійно обробляв незаповнені значення в даних і обробляв категоріальні колонки.\n",
    "\n",
    "  Аби передати категоріальні колонки в LightGBM - необхідно виявити їх індекси і передати в параметрі `cat_feature=cat_feature_indexes`\n",
    "\n",
    "  Після тренування моделі\n",
    "  1. Виміряйте точність з допомогою AUROC на тренувальному та валідаційному наборах.\n",
    "  2. Зробіть висновок про отриману модель: вона хороша/погана, чи є high bias/high variance?\n",
    "  3. Порівняйте якість цієї моделі з тою, що ви отрмали з використанням XGBoostClassifier раніше. Чи вийшло покращити якість?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C-9aZn4d45No"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nCnkGD_sEW1i"
   },
   "source": [
    "5. Використовуючи бібліотеку `Hyperopt` і приклад пошуку гіперпараметрів для `LightGBM` з лекції знайдіть оптимальні значення гіперпараметрів `LightGBM` для нашої задачі. Задайте свою сітку гіперпараметрів виходячи з тих параметрів, які ви б хотіли перебрати. Поставте кількість раундів в підборі гіперпараметрів рівну **10**.\n",
    "\n",
    "  **Увага!** Для того, аби скористатись hyperopt, нам треба задати функцію `objective`. І тут ми також ставимо loss - негативне значення AUROC, як і при пошуці гіперпараметрів для XGBoost. До речі, можна спробувати написати код так, аби в objective передавати лише модель і не писати схожий код двічі :)\n",
    "\n",
    "  Після успішного завершення пошуку оптимальних гіперпараметрів\n",
    "    - виведіть найкращі значення гіперпараметрів\n",
    "    - створіть в окремій зміній `final_lgb_clf` модель `LightGBM` з найкращими гіперпараметрами\n",
    "    - навчіть модель `final_lgb_clf`\n",
    "    - оцініть якість моделі `final_lgb_clf` на тренувальній і валідаційній вибірках з допомогою AUROC.\n",
    "    - зробіть висновок про якість моделі. Чи стала вона краще порівняно з попереднім пунктом (4) цього завдання?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cfMQKA4D47Rq"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XArADR2CG8VK"
   },
   "source": [
    "6. Оберіть модель з експериментів в цьому ДЗ і зробіть новий `submission` на Kaggle та додайте код для цього і скріншот скора на публічному лідерборді.\n",
    "  \n",
    "  **Напишіть коментар, чому ви обрали саме цю модель?**\n",
    "\n",
    "  І я вас вітаю - це останнє завдання з цим набором даних 💪 На цьому етапі корисно проаналізувати, які моделі показали себе найкраще і подумати, чому."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "COIjJH9f5SSp"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
